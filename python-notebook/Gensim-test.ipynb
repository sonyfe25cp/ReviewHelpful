{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "\"A survey of user opinion of computer system response time\",\n",
    "\"The EPS user interface management system\",\n",
    "\"System and human system engineering testing of EPS\",\n",
    "\"Relation of user perceived response time to error measurement\",\n",
    "\"The generation of random binary unordered trees\",\n",
    "\"The intersection graph of paths in trees\",\n",
    "\"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "\"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Human machine interface for lab abc computer applications',\n",
       " 'A survey of user opinion of computer system response time',\n",
       " 'The EPS user interface management system',\n",
       " 'System and human system engineering testing of EPS',\n",
       " 'Relation of user perceived response time to error measurement',\n",
       " 'The generation of random binary unordered trees',\n",
       " 'The intersection graph of paths in trees',\n",
       " 'Graph minors IV Widths of trees and well quasi ordering',\n",
       " 'Graph minors A survey']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'],\n",
       " ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'management', 'system'],\n",
       " ['system', 'human', 'system', 'engineering', 'testing', 'eps'],\n",
       " ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'],\n",
       " ['generation', 'random', 'binary', 'unordered', 'trees'],\n",
       " ['intersection', 'graph', 'paths', 'trees'],\n",
       " ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [[token for token in text if frequency[token] > 1]for text in texts]\n",
    "print texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: [u'minors', u'graph', u'system', u'trees', u'eps']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('/tmp/deerwester.dict')\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'minors': 11, u'graph': 10, u'system': 6, u'trees': 9, u'eps': 8, u'computer': 1, u'survey': 5, u'user': 7, u'human': 2, u'time': 4, u'interface': 0, u'response': 3}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (2, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)], [(1, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(0, 1), (6, 1), (7, 1), (8, 1)], [(2, 1), (6, 2), (8, 1)], [(3, 1), (4, 1), (7, 1)], [(9, 1)], [(9, 1), (10, 1)], [(9, 1), (10, 1), (11, 1)], [(5, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "# corpora.MmCorpus.serialize('/tmp/deerwester.mm', corpus)\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyCorpus object at 0x7f0632e49a50>\n"
     ]
    }
   ],
   "source": [
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        for line in open(\"/data/opinion_spam/real/10lines\"):\n",
    "            yield dictionary.doc2bow(line.lower().split())\n",
    "corpus_mem = MyCorpus()\n",
    "print corpus_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[(4, 2)]\n",
      "[(4, 1)]\n",
      "[(2, 1), (4, 1)]\n",
      "[]\n",
      "[]\n",
      "[(4, 2)]\n",
      "[(2, 1)]\n",
      "[]\n",
      "[(2, 1)]\n"
     ]
    }
   ],
   "source": [
    "for v in corpus_mem:\n",
    "    print v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(289 unique tokens: [u'impression', u'walking', u'just', u'show', u'when']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(line.lower().split() for line in open('/data/opinion_spam/real/10lines'))\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\n",
    "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq == 1]\n",
    "dictionary.filter_tokens(stop_ids + once_ids)\n",
    "dictionary.compactify()\n",
    "print dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1004AX2J2HXGL', 'B0007RT9LC', 'May', '30,', '2005', '3', '4', '5.0', 'The', 'film', 'speaks', 'for', 'itself', 'The', 'only', 'thing', 'missing', 'is', 'a', 'presentation', 'of', 'the', 'original', '78', 'minute', 'film', '\"Some', 'Folks', 'Call', 'it', 'a', 'Sling', 'Blade\"', '(1993)', 'which', 'later', 'the', 'feature', 'length', 'film', 'was', 'created', 'from.', \"Can't\", 'have', 'it', 'all,', 'I', 'guess.', 'Perhaps', 'when', 'they', 'release', 'the', 'extra-special', 'edition?', 'If', 'you', 'like', 'Bill', 'Bob', 'in', 'this', 'film,', 'you', 'should', 'also', 'check', 'out', '\"Dead', 'Man\"', \"(he's\", 'in', 'exactly', 'one', 'hilarious', 'scene)', 'and', '\"The', 'Man', 'Who', \"Wasn't\", 'There\".', 'Approximate', 'Run', 'Time:', '148', 'minutes', 'Bonus', 'Feature(s):', '*', 'Feature', 'Commentary', 'With', 'Writer/Director/Actor', 'Billy', 'Bob', 'Thornton', '*', 'Mr.', 'Thornton', 'Goes', 'To', 'Hollywood', '*', 'Bravo', 'Profiles:', 'Billy', 'Bob', 'Thornton', '*', 'A', 'Roundtable', 'Discussion', 'With', 'Billy', 'Bob', 'Thornton,', 'Dwight', 'Yoakam,', 'Mickey', 'Jones,', 'And', 'Producer', 'David', 'Bushell', '*', 'A', 'Conversation', 'With', 'Billy', 'Bob', 'Thornton', 'And', 'Robert', 'Duvall', '*', 'A', 'Conversation', 'With', 'Robert', 'Duvall', '*', 'A', 'Conversation', 'With', 'Billy', 'Bob', 'Thornton', 'And', 'Composer', 'Daniel', 'Lanois', '*', 'The', 'Return', 'Of', 'Karl', '*', 'On', 'The', 'Set:', 'Billy', 'Bob', 'At', 'Work;', \"Doyle's\", 'Band:', 'The', 'Johnsons;', 'Doyle', 'Gets', 'Pummeled;', '\"Doyle\\'s', 'Dead\"', 'With', 'Introduction', 'By', 'Billy', 'Bob', 'Thornton', '*', 'SLING', 'BLADE', 'Reviews', 'Technical', 'Features:', '*', 'Color', '*', '1.85:1', 'Aspect', 'Ratio', '*', 'Closed', 'Captioned', '*', 'Region', '1', '*', 'Spanish', 'Subtitles']\n",
      "Word2Vec(vocab=97, size=100, alpha=0.025)\n",
      "<type 'dict'>\n",
      "[  9.92219895e-04  -4.35117306e-03   9.99153359e-04  -1.88408652e-03\n",
      "   4.79384093e-03  -3.58331646e-03  -1.93625514e-04   2.89897248e-03\n",
      "  -2.87487288e-03   3.99341341e-03  -3.64450086e-03  -2.62784539e-03\n",
      "   1.13193120e-03   3.78601486e-03  -5.78440446e-03   1.01195637e-03\n",
      "   3.26990557e-05  -4.62992908e-03  -4.11010999e-03   3.80462408e-03\n",
      "  -3.30378790e-03   3.26574314e-03  -1.54706102e-03  -1.78582792e-04\n",
      "   4.57443902e-03  -3.75866960e-03  -8.51068355e-04   4.62452974e-03\n",
      "   6.64618798e-04  -6.42738864e-03   4.24723374e-03   4.97901626e-03\n",
      "   2.73781992e-03  -2.97664606e-04  -3.22258612e-03   2.92826182e-04\n",
      "   1.29352184e-03   7.85316993e-03   2.39539938e-03   1.83763588e-03\n",
      "  -2.86480784e-03   1.87771046e-03   5.40901348e-03  -4.83622262e-03\n",
      "  -5.63286711e-03   7.38873379e-04   2.91442545e-03   2.69877282e-03\n",
      "   3.99946328e-03   5.23633184e-03  -5.28496737e-03  -3.21196928e-03\n",
      "  -3.54050822e-03  -7.31165812e-04   2.98765465e-03  -1.45081757e-03\n",
      "   1.74453226e-03  -3.80229834e-03  -4.49609337e-03  -3.02314712e-03\n",
      "  -1.56215089e-03  -2.69433716e-03  -1.04316359e-03  -3.05123208e-03\n",
      "   3.23156407e-03   2.24721804e-03  -1.86434365e-03   5.83185523e-04\n",
      "   1.67933700e-03  -4.78478707e-03   4.31161374e-03  -1.32210681e-03\n",
      "  -1.92890363e-03   2.54256162e-03   2.98299827e-03  -3.11943993e-04\n",
      "   1.81353185e-03   2.59615667e-03   4.27730009e-03  -1.28824322e-03\n",
      "  -2.17605208e-04   5.06865745e-03  -1.78317889e-03  -3.99699295e-03\n",
      "  -2.46698316e-03  -6.08074805e-03   2.47243722e-03   3.63611570e-03\n",
      "   1.24766887e-03   1.90732488e-03  -8.11016653e-03   2.55178730e-03\n",
      "   4.41095443e-04   3.51349940e-03  -5.11967577e-04  -5.24869421e-03\n",
      "   3.38974618e-03   1.75327994e-03  -5.93320234e-03  -4.85293381e-03]\n"
     ]
    }
   ],
   "source": [
    "#Test w2v\n",
    "import gensim\n",
    "sentences = [[word for word in line.split()]for line in open('/data/opinion_spam/real/10lines')]\n",
    "print sentences[0]\n",
    "model_10 = gensim.models.Word2Vec(sentences, min_count=5, size=100, window=5, workers=8)\n",
    "print model_10\n",
    "print type(model_10.vocab)\n",
    "print model_10['film']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A1004AX2J2HXGL', 'B0007RT9LC', 'May', '30,', '2005', '3', '4', '5.0', 'The', 'film', 'speaks', 'for', 'itself', 'The', 'only', 'thing', 'missing', 'is', 'a', 'presentation', 'of', 'the', 'original', '78', 'minute', 'film', '\"Some', 'Folks', 'Call', 'it', 'a', 'Sling', 'Blade\"', '(1993)', 'which', 'later', 'the', 'feature', 'length', 'film', 'was', 'created', 'from.', \"Can't\", 'have', 'it', 'all,', 'I', 'guess.', 'Perhaps', 'when', 'they', 'release', 'the', 'extra-special', 'edition?', 'If', 'you', 'like', 'Bill', 'Bob', 'in', 'this', 'film,', 'you', 'should', 'also', 'check', 'out', '\"Dead', 'Man\"', \"(he's\", 'in', 'exactly', 'one', 'hilarious', 'scene)', 'and', '\"The', 'Man', 'Who', \"Wasn't\", 'There\".', 'Approximate', 'Run', 'Time:', '148', 'minutes', 'Bonus', 'Feature(s):', '*', 'Feature', 'Commentary', 'With', 'Writer/Director/Actor', 'Billy', 'Bob', 'Thornton', '*', 'Mr.', 'Thornton', 'Goes', 'To', 'Hollywood', '*', 'Bravo', 'Profiles:', 'Billy', 'Bob', 'Thornton', '*', 'A', 'Roundtable', 'Discussion', 'With', 'Billy', 'Bob', 'Thornton,', 'Dwight', 'Yoakam,', 'Mickey', 'Jones,', 'And', 'Producer', 'David', 'Bushell', '*', 'A', 'Conversation', 'With', 'Billy', 'Bob', 'Thornton', 'And', 'Robert', 'Duvall', '*', 'A', 'Conversation', 'With', 'Robert', 'Duvall', '*', 'A', 'Conversation', 'With', 'Billy', 'Bob', 'Thornton', 'And', 'Composer', 'Daniel', 'Lanois', '*', 'The', 'Return', 'Of', 'Karl', '*', 'On', 'The', 'Set:', 'Billy', 'Bob', 'At', 'Work;', \"Doyle's\", 'Band:', 'The', 'Johnsons;', 'Doyle', 'Gets', 'Pummeled;', '\"Doyle\\'s', 'Dead\"', 'With', 'Introduction', 'By', 'Billy', 'Bob', 'Thornton', '*', 'SLING', 'BLADE', 'Reviews', 'Technical', 'Features:', '*', 'Color', '*', '1.85:1', 'Aspect', 'Ratio', '*', 'Closed', 'Captioned', '*', 'Region', '1', '*', 'Spanish', 'Subtitles']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-7a9b71c4a8c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/data/opinion_spam/real/reviewsNew.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sentences, size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, cbow_mean, hashfxn, iter, null_word, trim_rule, sorted_vocab)\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGeneratorType\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You can't pass a generator as the sentences argument. Try an iterator.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mbuild_vocab\u001b[1;34m(self, sentences, keep_raw_vocab, trim_rule)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m         \"\"\"\n\u001b[1;32m--> 495\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# initial survey\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    496\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeep_raw_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_raw_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrim_rule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrim_rule\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# trim by min_count & precalculate downsampling\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinalize_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# build tables & arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/gensim/models/word2vec.pyc\u001b[0m in \u001b[0;36mscan_vocab\u001b[1;34m(self, sentences, progress_per, trim_rule)\u001b[0m\n\u001b[0;32m    509\u001b[0m                             sentence_no, sum(itervalues(vocab)) + total_words, len(vocab))\n\u001b[0;32m    510\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m                 \u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_vocab_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_vocab_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Test w2v\n",
    "import gensim\n",
    "sentences = [[word for word in line.split()]for line in open('/data/opinion_spam/real/reviewsNew.txt')]\n",
    "print sentences[0]\n",
    "model = gensim.models.Word2Vec(sentences, min_count=5, size=100, window=5, workers=8)\n",
    "print model\n",
    "print type(model.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for key in model.vocab:\n",
    "#    print key, \"===>\", model.vocab.get(key)\n",
    "#print model['cooking']\n",
    "#print len(model['cooking'])\n",
    "print model.similarity('computer', 'film')\n",
    "print model.similarity('movie', 'film')\n",
    "print model.similarity('book', 'film')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.save('/data/opinion_spam/real/w2v.total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-49b980bcf1be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'book'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'film'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "print model.similarity('book', 'film')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
