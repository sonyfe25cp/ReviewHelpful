{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = '/data/opinion_spam/real/reviewsNew.txt-utf8'\n",
    "datas = []\n",
    "MIN_FD = 100\n",
    "raw_file = open(file_path)\n",
    "debug = False\n",
    "debug_size = 100\n",
    "_debug_count = 0\n",
    "for line in raw_file:    \n",
    "    try:\n",
    "        line = line.decode('gbk')\n",
    "    except:\n",
    "        continue\n",
    "    #print 'gbk', line\n",
    "    line = line.encode('utf-8')\n",
    "    #print 'utf8', line\n",
    "    item = line.split('\\t')\n",
    "    if len(item) == 8:\n",
    "        hfd = float(item[3])\n",
    "        fd = float(item[4])\n",
    "        ratings = float(item[5])\n",
    "        if fd > MIN_FD:\n",
    "            hfdfd = round(hfd/fd, 2)\n",
    "            #whole_filted_body += item[7]\n",
    "            item.append(hfdfd)\n",
    "            datas.append(item)\n",
    "            if debug == True:\n",
    "                _debug_count += 1\n",
    "                if _debug_count >= debug_size:\n",
    "                    break\n",
    "raw_file.close()\n",
    "print 'datas.size: ', len(datas)\n",
    "print datas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set column names\n",
    "column_names = ['rid', 'pid', 'date', 'hfd', 'fd', 'rating', 'title', 'body', 'hfdfd']\n",
    "df = pd.DataFrame(datas)\n",
    "df.columns = column_names\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transfer the type of column\n",
    "df[['hfd', 'fd','rating']] = df[['hfd', 'fd', 'rating']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hfdfd distribution\n",
    "df.hfdfd.hist()\n",
    "plt.title='The Distribute of hfd/fd'\n",
    "plt.xlabel('Score of hfd/fd')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rating distribution\n",
    "df.rating.hist()\n",
    "plt.xlabel('Ratings')\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count how many products in the dataset  ==》9809 products\n",
    "df.groupby('pid').count().shape\n",
    "print 'different product size:', df.groupby('pid').count().shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['title_len'] = df['title'].apply(len)\n",
    "df['body_len'] = df['body'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['title_len'].hist()\n",
    "plt.xlabel('length of review title')\n",
    "plt.ylabel('counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df['body_len'] > 10][df['body_len'] < 5000]['body_len'].hist()\n",
    "plt.xlim(0, 5000)\n",
    "plt.xlabel(\"length of review body\")\n",
    "plt.ylabel(\"counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['title_len', 'body_len']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TFIDF feature without lsa\n",
    "\n",
    "import evaluation_self as es\n",
    "max_features_count = 10000\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, max_features=max_features_count,\n",
    "                                 min_df=2, stop_words='english', tokenizer = es.tokenize_and_stem)\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(df.body)\n",
    "print \"the tfidf matrix size : \",tfidf_matrix.shape\n",
    "print type(tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TFIDF-CV-10-lsvr\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "lsvr = LinearSVR()\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "scores2 = cross_val_score(lsvr, tfidf_matrix, df.hfdfd, cv=10, scoring=\"mean_squared_error\")\n",
    "\n",
    "mse2 = abs(scores2)\n",
    "print 'TFIDF-cv10-LSVR, mse:', mse2\n",
    "print 'TFIDF-cv10-LSVR, mse mean:', np.mean(mse2)\n",
    "print 'TFIDF-cv10-LSVR, rmse:', np.sqrt(mse2)\n",
    "print 'TFIDF-cv10-LSVR, rmse mean:', np.mean(np.sqrt(mse2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TFIDF-CV-10-svr\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "scores2 = cross_val_score(svr, tfidf_matrix, df.hfdfd, cv=10, scoring=\"mean_squared_error\")\n",
    "\n",
    "mse2 = abs(scores2)\n",
    "print 'TFIDF-cv10-SVR, mse:', mse2\n",
    "print 'TFIDF-cv10-SVR, mse mean:', np.mean(mse2)\n",
    "print 'TFIDF-cv10-SVR, rmse:', np.sqrt(mse2)\n",
    "print 'TFIDF-cv10-SVR, rmse mean:', np.mean(np.sqrt(mse2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TFIDF-CV-10-lr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "scores2 = cross_val_score(lr, tfidf_matrix, df.hfdfd, cv=10, scoring=\"mean_squared_error\")\n",
    "\n",
    "mse2 = abs(scores2)\n",
    "print 'TFIDF-cv10-LR, mse:', mse2\n",
    "print 'TFIDF-cv10-LR, mse mean:', np.mean(mse2)\n",
    "print 'TFIDF-cv10-LR, rmse:', np.sqrt(mse2)\n",
    "print 'TFIDF-cv10-LR, rmse mean:', np.mean(np.sqrt(mse2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF - LSA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TFIDF feature without lsa\n",
    "from time import time\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import evaluation_self as es\n",
    "max_features_count = 10000\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, max_features=max_features_count,\n",
    "                                 min_df=2, stop_words='english', tokenizer = es.tokenize_and_stem)\n",
    "lsa_tfidf_matrix = vectorizer.fit_transform(df.body)\n",
    "print \"the tfidf matrix size : \",tfidf_matrix.shape\n",
    "print type(tfidf_matrix)\n",
    "\n",
    "lsaornot = True\n",
    "lsanum = 1000\n",
    "\n",
    "if lsaornot:\n",
    "    print \"Performing dimensionality reduction using LSA\"\n",
    "    t0 = time()\n",
    "    # Vectorizer results are normalized, which makes KMeans behave as\n",
    "    # spherical k-means for better results. Since LSA/SVD results are\n",
    "    # not normalized, we have to redo the normalization.\n",
    "    svd = TruncatedSVD(lsanum)\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "    lsa_tfidf_matrix = lsa.fit_transform(tfidf_matrix)\n",
    "\n",
    "    print \"done in \", (time() - t0)\n",
    "    explained_variance = svd.explained_variance_ratio_.sum()\n",
    "    print \"Explained variance of the SVD step:\", int(explained_variance * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TFIDF-LSA-cv10-LR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "scores2 = cross_val_score(lr, lsa_tfidf_matrix, df.hfdfd, cv=10, scoring=\"mean_squared_error\")\n",
    "\n",
    "mse2 = abs(scores2)\n",
    "print 'TFIDF-LSA-cv10-LR, mse:', mse2\n",
    "print 'TFIDF-LSA-cv10-LR, mse mean:', np.mean(mse2)\n",
    "print 'TFIDF-LSA-cv10-LR, rmse2:', np.sqrt(mse2)\n",
    "print 'TFIDF-LSA-cv10-LR, rmse2 mean:', np.mean(np.sqrt(mse2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TFIDF-LSA-CV-10-lsvr\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "lsvr = LinearSVR()\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "scores2 = cross_val_score(lsvr, lsa_tfidf_matrix, df.hfdfd, cv=10, scoring=\"mean_squared_error\")\n",
    "\n",
    "mse2 = abs(scores2)\n",
    "print 'TFIDF-cv10-LSVR, mse:', mse2\n",
    "print 'TFIDF-cv10-LSVR, mse mean:', np.mean(mse2)\n",
    "print 'TFIDF-cv10-LSVR, rmse:', np.sqrt(mse2)\n",
    "print 'TFIDF-cv10-LSVR, rmse mean:', np.mean(np.sqrt(mse2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TFIDF-LSA-CV-10-svr\n",
    "t0 = time()\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "scores2 = cross_val_score(svr, lsa_tfidf_matrix, df.hfdfd, cv=10, scoring=\"mean_squared_error\")\n",
    "\n",
    "mse2 = abs(scores2)\n",
    "print 'TFIDF-cv10-SVR, mse:', mse2\n",
    "print 'TFIDF-cv10-SVR, mse mean:', np.mean(mse2)\n",
    "print 'TFIDF-cv10-SVR, rmse:', np.sqrt(mse2)\n",
    "print 'TFIDF-cv10-SVR, rmse mean:', np.mean(np.sqrt(mse2))\n",
    "print \"tfidf-svr cost:\", (time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STD features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#STD features\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "def seg_sentence(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return [s.strip() for s in sentences if(len(s)) > 0]\n",
    "\n",
    "def marks_num(text, pattern):\n",
    "    return len(re.findall(pattern, text))\n",
    "\n",
    "std_exc = 0\n",
    "def std_feature(text): # std in Yang@acl-2015\n",
    "#    print '==============================='\n",
    "    ary = [0, 0, 0, 0, 0]\n",
    "    try:\n",
    "        tokens = es.tokenize_and_stem(text)\n",
    "        token_num = len(tokens)\n",
    "    #    print 'token size:', token_num\n",
    "        sentences = seg_sentence(text)\n",
    "        sen_num = len(sentences)\n",
    "    #    print 'sentence size:', sen_num\n",
    "        avg_sentence_len = np.mean([len(x) for x in sentences])\n",
    "    #    print 'avg sentence length:', avg_sentence_len\n",
    "        exc_num = marks_num(text, r'[!！]')\n",
    "    #    print 'exclamation marks count:', exc_num\n",
    "        que_num = marks_num(text, r'[？?]')\n",
    "    #    print 'question percentage:', float(que_num) / sen_num\n",
    "        ary = [token_num, sen_num, avg_sentence_len, exc_num, que_num]\n",
    "#         print ary\n",
    "    except:\n",
    "#         print text\n",
    "        std_exc += 1\n",
    "    finally:\n",
    "        return ary\n",
    "    \n",
    "for loc in range(1, 10):\n",
    "    print std(df.body.head(10)[loc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#generate std features\n",
    "\n",
    "\n",
    "X_std = np.array(df.body)\n",
    "print type(X_std)\n",
    "X_std = np.array(map(std_feature, X_std))\n",
    "print \"std exception: \", std_exc\n",
    "\n",
    "print type(X_std)\n",
    "print X_std.shape\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "std_normalizer = Normalizer().fit(X_std)\n",
    "X_std = std_normalizer.transform(X_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#std-cv10-lr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "std_lr = LinearRegression()\n",
    "\n",
    "std_scores = cross_val_score(std_lr, X_std, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'STD-cv10-LR, mse:', std_mse\n",
    "print 'STD-cv10-LR, mse mean:', np.mean(std_mse)\n",
    "print 'STD-cv10-LR, rmse:', np.sqrt(std_mse)\n",
    "print 'STD-cv10-LR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#std-cv10-lsvr\n",
    "from sklearn.svm import LinearSVR\n",
    "std_lsvr = LinearSVR()\n",
    "\n",
    "std_scores = cross_val_score(std_lsvr, X_std, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'STD-cv10-LSVR, mse:', std_mse\n",
    "print 'STD-cv10-LSVR, mse mean:', np.mean(std_mse)\n",
    "print 'STD-cv10-LSVR, rmse:', np.sqrt(std_mse)\n",
    "print 'STD-cv10-LSVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#std-cv10-svr\n",
    "t0 = time()\n",
    "from sklearn.svm import SVR\n",
    "std_svr = SVR()\n",
    "\n",
    "std_scores = cross_val_score(std_svr, X_std, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'STD-cv10-SVR, mse:', std_mse\n",
    "print 'STD-cv10-SVR, mse mean:', np.mean(std_mse)\n",
    "print 'STD-cv10-SVR, rmse:', np.sqrt(std_mse)\n",
    "print 'STD-cv10-SVR, rmse mean:', np.mean(np.sqrt(std_mse))\n",
    "print \"STD-svr cost:\", (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def cut sentence\n",
    "stop_words = 'a,able,about,across,after,all,almost,also,am,among,an,and,any,are,as,at,be,because,been,but,by,can,cannot,could,dear,did,do,does,either,else,ever,every,for,from,get,got,had,has,have,he,her,hers,him,his,how,however,i,if,in,into,is,it,its,just,least,let,like,likely,may,me,might,most,must,my,neither,no,nor,not,of,off,often,on,only,or,other,our,own,rather,said,say,says,she,should,since,so,some,than,that,the,their,them,then,there,these,they,this,tis,to,too,twas,us,wants,was,we,were,what,when,where,which,while,who,whom,why,will,with,would,yet,you,your'\n",
    "stop_words_list = stop_words.split(',')\n",
    "\n",
    "def cut_into_tokens(text):\n",
    "\n",
    "    _list = [word.lower() for sentence in nltk.sent_tokenize(text) for word in sentence.split()]\n",
    "    _list = [re.sub(r'[.?!\\'\",)(;&%:]', '', word) for word in _list  ]\n",
    "    _list = [word for word in _list if word not in stop_words_list and len(word) > 0]\n",
    "    return _list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntactic features of Kim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Syntactic features of Kim\n",
    "\n",
    "text = df.body.head(1)[0]\n",
    "print text\n",
    "#print nltk.pos_tag([word  for sentence in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sentence)])\n",
    "\n",
    "def pos_count(text):\n",
    "    poses = nltk.pos_tag(cut_into_tokens(text))\n",
    "#     poses = nltk.pos_tag([word  for sentence in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sentence)])\n",
    "    pos_dict = {}\n",
    "    for (word, pos) in poses:\n",
    "        if pos in pos_dict:\n",
    "            pos_dict[pos] = pos_dict[pos] + 1\n",
    "        else:\n",
    "            pos_dict[pos] = 1\n",
    "    return pos_dict\n",
    "\n",
    "pos_dict = pos_count(text)#per sentence per second!!!!\n",
    "# for pos in pos_dict:\n",
    "#     print pos, \" => \", pos_dict[pos]\n",
    "# print 'aa'\n",
    "syn_exc = 0\n",
    "\n",
    "def fetch_count_from_pos_dict(pos_list, pos_dict):\n",
    "    _pos_count = 0\n",
    "    for pos in pos_list:\n",
    "        if pos in pos_dict:\n",
    "            _pos_count += pos_dict[pos]\n",
    "    return _pos_count\n",
    "\n",
    "def syntactic_feature(text): #syn feature function\n",
    "    ary = [0, 0, 0, 0]\n",
    "    try:\n",
    "        pos_dict = pos_count(text)\n",
    "        nn_count = fetch_count_from_pos_dict(['NN', 'NNS', 'NNP', 'NNPS'], pos_dict)#noun\n",
    "        jj_count = fetch_count_from_pos_dict(['JJ', 'JJR', 'JJS'], pos_dict)#adj\n",
    "        vb_count = fetch_count_from_pos_dict(['VB', 'VBD', 'VBG', 'VBN', 'VNP', 'VBZ'], pos_dict)#vb\n",
    "        rb_count = fetch_count_from_pos_dict(['RB', 'RBR', 'RBS'], pos_dict)#adv\n",
    "        ary = [nn_count, jj_count, vb_count, rb_count]\n",
    "    except:\n",
    "        print 'error'\n",
    "        syn_exc += 1\n",
    "    finally:\n",
    "        return ary\n",
    "# print 't_dict', pos_dict['_t_dict']\n",
    "for _text in df.body.head(10):\n",
    "    print syntactic_feature(_text)\n",
    "print 'syn_exc is ', syn_exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_syn = []\n",
    "for _body in df.body:\n",
    "    _v = syntactic_feature(_body)\n",
    "    X_syn.append(_v)\n",
    "print len(X_syn)\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "syn_normalizer = Normalizer()\n",
    "syn_normalizer.fit(X_syn)\n",
    "X_syn = syn_normalizer.transform(X_syn)\n",
    "\n",
    "# print X_w2v\n",
    "print syn_normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#syn-cv-10-LR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "syn_lr = LinearRegression()\n",
    "\n",
    "std_scores = cross_val_score(syn_lr, X_syn, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'SYN-cv10-LR, mse:', std_mse\n",
    "print 'SYN-cv10-LR, mse mean:', np.mean(std_mse)\n",
    "print 'SYN-cv10-LR, rmse:', np.sqrt(std_mse)\n",
    "print 'SYN-cv10-LR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#syn-cv-10-LSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "syn_lsvr = LinearSVR()\n",
    "\n",
    "std_scores = cross_val_score(syn_lsvr, X_syn, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'SYN-cv10-LSVR, mse:', std_mse\n",
    "print 'SYN-cv10-LSVR, mse mean:', np.mean(std_mse)\n",
    "print 'SYN-cv10-LSVR, rmse:', np.sqrt(std_mse)\n",
    "print 'SYN-cv10-LSVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#syn-cv-10-SVR\n",
    "t0 = time()\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "syn_lsvr = SVR()\n",
    "\n",
    "std_scores = cross_val_score(syn_lsvr, X_syn, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'SYN-cv10-SVR, mse:', std_mse\n",
    "print 'SYN-cv10-SVR, mse mean:', np.mean(std_mse)\n",
    "print 'SYN-cv10-SVR, rmse:', np.sqrt(std_mse)\n",
    "print 'SYN-cv10-SVR, rmse mean:', np.mean(np.sqrt(std_mse))\n",
    "print \"SYN-svr cost:\", (time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#w2v features\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "import gensim\n",
    "\n",
    "#load model\n",
    "fname = '/data/opinion_spam/real/w2v-hfd-over-0.total'\n",
    "#gensim.models.Word2Vec(sentences, min_count=5, size=100, window=5, workers=32)\n",
    "model = gensim.models.Word2Vec.load(fname)\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_with_sentence(sentence, model):\n",
    "    tokens = cut_into_tokens(sentence)\n",
    "    v = np.zeros(100)\n",
    "    _error = 0\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            _v = model[token]\n",
    "            v += _v\n",
    "        except:\n",
    "            _error += 1\n",
    "#             print 'token:', token, 'not in the dict'\n",
    "    return v\n",
    "print 'def model_with_sentence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_w2v = []\n",
    "for _body in df.body:\n",
    "    _v = model_with_sentence(_body, model)\n",
    "    X_w2v.append(_v)\n",
    "print len(X_w2v)\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "w2v_normalizer = Normalizer()\n",
    "w2v_normalizer.fit(X_w2v)\n",
    "X_w2v = w2v_normalizer.transform(X_w2v)\n",
    "\n",
    "# print X_w2v\n",
    "print w2v_normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#w2v-cv-10-LR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "w2v_lr = LinearRegression()\n",
    "\n",
    "std_scores = cross_val_score(w2v_lr, X_w2v, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'W2V-cv10-LR, mse:', std_mse\n",
    "print 'W2V-cv10-LR, mse mean:', np.mean(std_mse)\n",
    "print 'W2V-cv10-LR, rmse:', np.sqrt(std_mse)\n",
    "print 'W2V-cv10-LR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#w2v-cv-10-LSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "w2v_lsvr = LinearSVR()\n",
    "\n",
    "std_scores = cross_val_score(w2v_lsvr, X_w2v, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'W2V-cv10-LSVR, mse:', std_mse\n",
    "print 'W2V-cv10-LSVR, mse mean:', np.mean(std_mse)\n",
    "print 'W2V-cv10-LSVR, rmse:', np.sqrt(std_mse)\n",
    "print 'W2V-cv10-LSVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#w2v-cv-10-SVR\n",
    "t0 = time()\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "w2v_svr = SVR()\n",
    "\n",
    "std_scores = cross_val_score(w2v_svr, X_w2v, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'W2V-cv10-SVR, mse:', std_mse\n",
    "print 'W2V-cv10-SVR, mse mean:', np.mean(std_mse)\n",
    "print 'W2V-cv10-SVR, rmse:', np.sqrt(std_mse)\n",
    "print 'W2V-cv10-SVR, rmse mean:', np.mean(np.sqrt(std_mse))\n",
    "print \"W2V-svr cost:\", (time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils for merge features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_to_array(_matrix):\n",
    "    _dense = _matrix.todense()\n",
    "    _list = _dense.tolist()\n",
    "    return _list\n",
    "\n",
    "def append_matrix_to_matrix(array1, array2):\n",
    "    length = len(array1)#row num\n",
    "    new_matrix = []\n",
    "    for index in range(length):\n",
    "        _row = np.append(array1[index], array2[index])\n",
    "        new_matrix.append(_row)\n",
    "    return new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#validate the matrix merge\n",
    "ar1 = [[1,2,3],[2,3,4]]\n",
    "ar2 = [[5,6,7], [7,8,9]]\n",
    "ar3 = append_matrix_to_matrix(ar1, ar2)\n",
    "print ar3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STD + Word2Vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combine std + w2v\n",
    "# X_std_w2v = []\n",
    "# for _body in df.body:\n",
    "#     _w2v = model_with_sentence(_body, model)\n",
    "#     _std = std(_body)\n",
    "#     _v = np.append(_w2v, _std)\n",
    "#     X_std_w2v.append(_v)\n",
    "# print 'feature size : ', len(X_std_w2v[0])\n",
    "\n",
    "# std_w2v_normalizer = Normalizer()\n",
    "# std_w2v_normalizer.fit(X_w2v)\n",
    "# X_std_w2v = std_w2v_normalizer.transform(X_w2v)\n",
    "\n",
    "# print X_w2v\n",
    "# print std_w2v_normalizer\n",
    "\n",
    "X_std_w2v = append_matrix_to_matrix(X_std, X_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#std+w2v-cv-10-LR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "std_w2v_lr = LinearRegression()\n",
    "\n",
    "std_scores = cross_val_score(std_w2v_lr, X_std_w2v, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'STD+W2V-cv10-LR, mse:', std_mse\n",
    "print 'STD+W2V-cv10-LR, mse mean:', np.mean(std_mse)\n",
    "print 'STD+W2V-cv10-LR, rmse:', np.sqrt(std_mse)\n",
    "print 'STD+W2V-cv10-LR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#std+w2v-cv-10-LSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "std_w2v_lsvr = LinearSVR()\n",
    "\n",
    "std_scores = cross_val_score(std_w2v_lsvr, X_std_w2v, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'STD+W2V-cv10-LSVR, mse:', std_mse\n",
    "print 'STD+W2V-cv10-LSVR, mse mean:', np.mean(std_mse)\n",
    "print 'STD+W2V-cv10-LSVR, rmse:', np.sqrt(std_mse)\n",
    "print 'STD+W2V-cv10-LSVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#std+w2v-cv-10-SVR\n",
    "t0 = time()\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "std_w2v_svr = SVR()\n",
    "\n",
    "std_scores = cross_val_score(std_w2v_svr, X_std_w2v, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'STD+W2V-cv10-SVR, mse:', std_mse\n",
    "print 'STD+W2V-cv10-SVR, mse mean:', np.mean(std_mse)\n",
    "print 'STD+W2V-cv10-SVR, rmse:', np.sqrt(std_mse)\n",
    "print 'STD+W2V-cv10-SVR, rmse mean:', np.mean(np.sqrt(std_mse))\n",
    "print \"STD+W2V-svr cost:\", (time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# STD + SYN features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_std_syn = []\n",
    "# for _body in df.body:\n",
    "#     _std = std(_body)\n",
    "#     _syn = syntactic_feature(_body)\n",
    "#     _v = np.append(_std, _syn)\n",
    "#     X_std_syn.append(_v)\n",
    "# print 'feature size : ', len(X_std_syn[0])\n",
    "\n",
    "# std_syn_normalizer = Normalizer()\n",
    "# std_syn_normalizer.fit(X_std_syn)\n",
    "# X_std_syn = std_syn_normalizer.transform(X_std_syn)\n",
    "\n",
    "# # print X_w2v\n",
    "# print std_syn_normalizer\n",
    "\n",
    "X_std_syn = append_matrix_to_matrix(X_std, X_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#std+syn-cv-10-LR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "std_syn_lr = LinearRegression()\n",
    "\n",
    "std_scores = cross_val_score(std_syn_lr, X_std_syn, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'STD+SYN-cv10-LR, mse:', std_mse\n",
    "print 'STD+SYN-cv10-LR, mse mean:', np.mean(std_mse)\n",
    "print 'STD+SYN-cv10-LR, rmse:', np.sqrt(std_mse)\n",
    "print 'STD+SYN-cv10-LR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#std+syn-cv-10-LSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "std_syn_lsvr = LinearSVR()\n",
    "\n",
    "std_scores = cross_val_score(std_syn_lsvr, X_std_syn, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'STD+SYN-cv10-LSVR, mse:', std_mse\n",
    "print 'STD+SYN-cv10-LSVR, mse mean:', np.mean(std_mse)\n",
    "print 'STD+SYN-cv10-LSVR, rmse:', np.sqrt(std_mse)\n",
    "print 'STD+SYN-cv10-LSVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#std+syn-cv-10-SVR\n",
    "t0 = time()\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "std_syn_svr = SVR()\n",
    "\n",
    "std_scores = cross_val_score(std_syn_svr, X_std_syn, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'STD+SYN-cv10-SVR, mse:', std_mse\n",
    "print 'STD+SYN-cv10-SVR, mse mean:', np.mean(std_mse)\n",
    "print 'STD+SYN-cv10-SVR, rmse:', np.sqrt(std_mse)\n",
    "print 'STD+SYN-cv10-SVR, rmse mean:', np.mean(np.sqrt(std_mse))\n",
    "print 'cost : ', time()-t0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STD + SYN + W2V features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_std_syn_w2v = []\n",
    "# for _body in df.body:\n",
    "#     _std = std(_body)\n",
    "#     _syn = syntactic_feature(_body)\n",
    "#     _w2v = model_with_sentence(_body, model)\n",
    "#     _v = np.append(_std, _syn)\n",
    "#     _v = np.append(_v, _w2v)\n",
    "#     X_std_syn_w2v.append(_v)\n",
    "# print 'feature size : ', len(X_std_syn_w2v[0])\n",
    "\n",
    "# std_syn_w2v_normalizer = Normalizer()\n",
    "# std_syn_w2v_normalizer.fit(X_std_syn)\n",
    "# X_std_syn_w2v = std_syn_w2v_normalizer.transform(X_std_syn)\n",
    "\n",
    "# # print X_w2v\n",
    "# print std_syn_w2v_normalizer\n",
    "\n",
    "X_std_syn_w2v = []\n",
    "# X_std_syn_w2v = append_matrix_to_matrix(X_std_syn, X_w2v)\n",
    "X_std_syn_w2v = append_matrix_to_matrix(X_std, X_w2v)\n",
    "X_std_syn_w2v = append_matrix_to_matrix(X_std_syn_w2v, X_syn)\n",
    "print 'row size: ',len(X_std_syn_w2v)\n",
    "print 'column size: ',len(X_std_syn_w2v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#std+syn+w2v-cv-10-LR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "std_syn_w2v_lr = LinearRegression()\n",
    "\n",
    "std_scores = cross_val_score(std_syn_w2v_lr, X_std_syn_w2v, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'STD+SYN+W2V-cv10-LR, mse:', std_mse\n",
    "print 'STD+SYN+W2V-cv10-LR, mse mean:', np.mean(std_mse)\n",
    "print 'STD+SYN+W2V-cv10-LR, rmse:', np.sqrt(std_mse)\n",
    "print 'STD+SYN+W2V-cv10-LR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#std+syn+w2v-cv-10-LSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "std_syn_w2v_lsvr = LinearSVR()\n",
    "\n",
    "std_scores = cross_val_score(std_syn_w2v_lsvr, X_std_syn_w2v, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'STD+SYN+W2V-cv10-LSVR, mse:', std_mse\n",
    "print 'STD+SYN+W2V-cv10-LSVR, mse mean:', np.mean(std_mse)\n",
    "print 'STD+SYN+W2V-cv10-LSVR, rmse:', np.sqrt(std_mse)\n",
    "print 'STD+SYN+W2V-cv10-LSVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#std+syn+w2v-cv-10-LSVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "std_syn_w2v_svr = SVR()\n",
    "\n",
    "std_scores = cross_val_score(std_syn_w2v_svr, X_std_syn_w2v, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'STD+SYN+W2V-cv10-SVR, mse:', std_mse\n",
    "print 'STD+SYN+W2V-cv10-SVR, mse mean:', np.mean(std_mse)\n",
    "print 'STD+SYN+W2V-cv10-SVR, rmse:', np.sqrt(std_mse)\n",
    "print 'STD+SYN+W2V-cv10-SVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TFIDF + STD features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combine tfidf+std\n",
    "X_tfidf_std = []\n",
    "print 'tfidf_matrix type : ', type(tfidf_matrix)\n",
    "X_tfidf_std = append_matrix_to_matrix(matrix_to_array(tfidf_matrix), X_std)\n",
    "print 'row size: ',len(X_tfidf_std)\n",
    "print 'column size: ',len(X_tfidf_std[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tfidf+std-cv-10-LR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "tfidf_std_lr = LinearRegression()\n",
    "\n",
    "std_scores = cross_val_score(tfidf_std_lr, X_tfidf_std, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'TFIDF+STD-cv10-LR, mse:', std_mse\n",
    "print 'TFIDF+STD-cv10-LR, mse mean:', np.mean(std_mse)\n",
    "print 'TFIDF+STD-cv10-LR, rmse:', np.sqrt(std_mse)\n",
    "print 'TFIDF+STD-cv10-LR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tfidf+std-cv-10-LSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "tfidf_std_lsvr = LinearSVR()\n",
    "\n",
    "std_scores = cross_val_score(tfidf_std_lsvr, X_tfidf_std, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'TFIDF+STD-cv10-LSVR, mse:', std_mse\n",
    "print 'TFIDF+STD-cv10-LSVR, mse mean:', np.mean(std_mse)\n",
    "print 'TFIDF+STD-cv10-LSVR, rmse:', np.sqrt(std_mse)\n",
    "print 'TFIDF+STD-cv10-LSVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tfidf+std-cv-10-LSVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "tfidf_std_svr = SVR()\n",
    "\n",
    "std_scores = cross_val_score(tfidf_std_svr, X_tfidf_std, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'TFIDF+STD-cv10-SVR, mse:', std_mse\n",
    "print 'TFIDF+STD-cv10-SVR, mse mean:', np.mean(std_mse)\n",
    "print 'TFIDF+STD-cv10-SVR, rmse:', np.sqrt(std_mse)\n",
    "print 'TFIDF+STD-cv10-SVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# TFIDF + STD + SYN features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tfidf_std_syn = []\n",
    "X_tfidf_std_syn = append_matrix_to_matrix(X_tfidf_std, X_syn)\n",
    "print 'row size: ',len(X_tfidf_std_syn)\n",
    "print 'column size: ',len(X_tfidf_std_syn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tfidf+std+syn-cv-10-LR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "tfidf_std_syn_lr = LinearRegression()\n",
    "\n",
    "std_scores = cross_val_score(tfidf_std_syn_lr, X_tfidf_std_syn, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'TFIDF+STD+SYN-cv10-LR, mse:', std_mse\n",
    "print 'TFIDF+STD+SYN-cv10-LR, mse mean:', np.mean(std_mse)\n",
    "print 'TFIDF+STD+SYN-cv10-LR, rmse:', np.sqrt(std_mse)\n",
    "print 'TFIDF+STD+SYN-cv10-LR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tfidf+std-cv-10-LSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "tfidf_std_syn_lsvr = LinearRegression()\n",
    "\n",
    "std_scores = cross_val_score(tfidf_std_syn_lsvr, X_tfidf_std_syn, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'TFIDF+STD+SYN-cv10-LSVR, mse:', std_mse\n",
    "print 'TFIDF+STD+SYN-cv10-LSVR, mse mean:', np.mean(std_mse)\n",
    "print 'TFIDF+STD+SYN-cv10-LSVR, rmse:', np.sqrt(std_mse)\n",
    "print 'TFIDF+STD+SYN-cv10-LSVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tfidf+std-cv-10-LSVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "tfidf_std_syn_svr = SVR()\n",
    "\n",
    "std_scores = cross_val_score(tfidf_std_syn_svr, X_tfidf_std_syn, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'TFIDF+STD+SYN-cv10-SVR, mse:', std_mse\n",
    "print 'TFIDF+STD+SYN-cv10-SVR, mse mean:', np.mean(std_mse)\n",
    "print 'TFIDF+STD+SYN-cv10-SVR, rmse:', np.sqrt(std_mse)\n",
    "print 'TFIDF+STD+SYN-cv10-SVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF + STD + SYN + W2V features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tfidf_std_syn_w2v = []\n",
    "X_tfidf_std_syn_w2v = append_matrix_to_matrix(X_tfidf_std_syn, X_w2v)\n",
    "print 'row size: ',len(X_tfidf_std_syn_w2v)\n",
    "print 'column size: ',len(X_tfidf_std_syn_w2v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tfidf+std+syn-cv-10-LR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "tfidf_std_syn_w2v_lr = LinearRegression()\n",
    "\n",
    "std_scores = cross_val_score(tfidf_std_syn_w2v_lr, X_tfidf_std_syn_w2v, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'TFIDF+STD+SYN+W2V-cv10-LR, mse:', std_mse\n",
    "print 'TFIDF+STD+SYN+W2V-cv10-LR, mse mean:', np.mean(std_mse)\n",
    "print 'TFIDF+STD+SYN+W2V-cv10-LR, rmse:', np.sqrt(std_mse)\n",
    "print 'TFIDF+STD+SYN+W2V-cv10-LR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tfidf+std+syn-cv-10-LR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "tfidf_std_syn_w2v_lsvr = LinearSVR()\n",
    "\n",
    "std_scores = cross_val_score(tfidf_std_syn_w2v_lsvr, X_tfidf_std_syn_w2v, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'TFIDF+STD+SYN+W2V-cv10-LSVR, mse:', std_mse\n",
    "print 'TFIDF+STD+SYN+W2V-cv10-LSVR, mse mean:', np.mean(std_mse)\n",
    "print 'TFIDF+STD+SYN+W2V-cv10-LSVR, rmse:', np.sqrt(std_mse)\n",
    "print 'TFIDF+STD+SYN+W2V-cv10-LSVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tfidf+std+syn-cv-10-SVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "tfidf_std_syn_w2v_svr = SVR()\n",
    "\n",
    "std_scores = cross_val_score(tfidf_std_syn_w2v_svr, X_tfidf_std_syn_w2v, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'TFIDF+STD+SYN+W2V-cv10-SVR, mse:', std_mse\n",
    "print 'TFIDF+STD+SYN+W2V-cv10-SVR, mse mean:', np.mean(std_mse)\n",
    "print 'TFIDF+STD+SYN+W2V-cv10-SVR, rmse:', np.sqrt(std_mse)\n",
    "print 'TFIDF+STD+SYN+W2V-cv10-SVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF+LSA + STD features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combine tfidf+std\n",
    "X_lsa_tfidf_std = []\n",
    "print 'lsa_tfidf_matrix type: ', type(lsa_tfidf_matrix)\n",
    "X_lsa_tfidf_std = append_matrix_to_matrix(lsa_tfidf_matrix, X_std)\n",
    "print 'row size: ',len(X_lsa_tfidf_std)\n",
    "print 'column size: ',len(X_lsa_tfidf_std[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lsa+tfidf+std-cv-10-LR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lsa_tfidf_std_lr = LinearRegression()\n",
    "\n",
    "std_scores = cross_val_score(lsa_tfidf_std_lr, X_lsa_tfidf_std, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'LSA+TFIDF+STD-cv10-LR, mse:', std_mse\n",
    "print 'LSA+TFIDF+STD-cv10-LR, mse mean:', np.mean(std_mse)\n",
    "print 'LSA+TFIDF+STD-cv10-LR, rmse:', np.sqrt(std_mse)\n",
    "print 'LSA+TFIDF+STD-cv10-LR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lsa+tfidf+std-cv-10-LSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "lsa_tfidf_std_lsvr = LinearSVR()\n",
    "\n",
    "std_scores = cross_val_score(lsa_tfidf_std_lsvr, X_lsa_tfidf_std, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'LSA+TFIDF+STD-cv10-LSVR, mse:', std_mse\n",
    "print 'LSA+TFIDF+STD-cv10-LSVR, mse mean:', np.mean(std_mse)\n",
    "print 'LSA+TFIDF+STD-cv10-LSVR, rmse:', np.sqrt(std_mse)\n",
    "print 'LSA+TFIDF+STD-cv10-LSVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lsa+tfidf+std-cv-10-SVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "lsa_tfidf_std_lsvr = SVR()\n",
    "\n",
    "std_scores = cross_val_score(lsa_tfidf_std_lsvr, X_lsa_tfidf_std, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'LSA+TFIDF+STD-cv10-SVR, mse:', std_mse\n",
    "print 'LSA+TFIDF+STD-cv10-SVR, mse mean:', np.mean(std_mse)\n",
    "print 'LSA+TFIDF+STD-cv10-SVR, rmse:', np.sqrt(std_mse)\n",
    "print 'LSA+TFIDF+STD-cv10-SVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA+TFIDF + STD + SYN features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_lsa_tfidf_std_syn = []\n",
    "X_lsa_tfidf_std_syn = append_matrix_to_matrix(X_lsa_tfidf_std, X_syn)\n",
    "print 'row size: ',len(X_lsa_tfidf_std_syn)\n",
    "print 'column size: ',len(X_lsa_tfidf_std_syn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lsa+tfidf+std-cv-10-LR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lsa_tfidf_std_syn_lr = LinearRegression()\n",
    "\n",
    "std_scores = cross_val_score(lsa_tfidf_std_syn_lr, X_lsa_tfidf_std_syn, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'LSA+TFIDF+STD+SYN-cv10-LR, mse:', std_mse\n",
    "print 'LSA+TFIDF+STD+SYN-cv10-LR, mse mean:', np.mean(std_mse)\n",
    "print 'LSA+TFIDF+STD+SYN-cv10-LR, rmse:', np.sqrt(std_mse)\n",
    "print 'LSA+TFIDF+STD+SYN-cv10-LR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lsa+tfidf+std-cv-10-LSVR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "lsa_tfidf_std_syn_lsvr = LinearSVR()\n",
    "\n",
    "std_scores = cross_val_score(lsa_tfidf_std_syn_lsvr, X_lsa_tfidf_std_syn, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'LSA+TFIDF+STD+SYN-cv10-LSVR, mse:', std_mse\n",
    "print 'LSA+TFIDF+STD+SYN-cv10-LSVR, mse mean:', np.mean(std_mse)\n",
    "print 'LSA+TFIDF+STD+SYN-cv10-LSVR, rmse:', np.sqrt(std_mse)\n",
    "print 'LSA+TFIDF+STD+SYN-cv10-LSVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lsa+tfidf+std-cv-10-SVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "lsa_tfidf_std_syn_svr = SVR()\n",
    "\n",
    "std_scores = cross_val_score(lsa_tfidf_std_syn_svr, X_lsa_tfidf_std_syn, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'LSA+TFIDF+STD+SYN-cv10-SVR, mse:', std_mse\n",
    "print 'LSA+TFIDF+STD+SYN-cv10-SVR, mse mean:', np.mean(std_mse)\n",
    "print 'LSA+TFIDF+STD+SYN-cv10-SVR, rmse:', np.sqrt(std_mse)\n",
    "print 'LSA+TFIDF+STD+SYN-cv10-SVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA+TFIDF + STD + SYN + W2V features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_lsa_tfidf_std_syn_w2v = []\n",
    "X_lsa_tfidf_std_syn_w2v = append_matrix_to_matrix(X_lsa_tfidf_std_syn, X_w2v)\n",
    "print 'row size: ',len(X_lsa_tfidf_std_syn_w2v)\n",
    "print 'column size: ',len(X_lsa_tfidf_std_syn_w2v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lsa+tfidf+std-cv-10-LR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lsa_tfidf_std_syn_w2v_lr = LinearRegression()\n",
    "\n",
    "std_scores = cross_val_score(lsa_tfidf_std_syn_w2v_lr, X_lsa_tfidf_std_syn_w2v, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'LSA+TFIDF+STD+SYN+W2V-cv10-LR, mse:', std_mse\n",
    "print 'LSA+TFIDF+STD+SYN+W2V-cv10-LR, mse mean:', np.mean(std_mse)\n",
    "print 'LSA+TFIDF+STD+SYN+W2V-cv10-LR, rmse:', np.sqrt(std_mse)\n",
    "print 'LSA+TFIDF+STD+SYN+W2V-cv10-LR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lsa+tfidf+std-cv-10-LR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "lsa_tfidf_std_syn_w2v_lsvr = LinearSVR()\n",
    "\n",
    "std_scores = cross_val_score(lsa_tfidf_std_syn_w2v_lsvr, X_lsa_tfidf_std_syn_w2v, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'LSA+TFIDF+STD+SYN+W2V-cv10-LSVR, mse:', std_mse\n",
    "print 'LSA+TFIDF+STD+SYN+W2V-cv10-LSVR, mse mean:', np.mean(std_mse)\n",
    "print 'LSA+TFIDF+STD+SYN+W2V-cv10-LSVR, rmse:', np.sqrt(std_mse)\n",
    "print 'LSA+TFIDF+STD+SYN+W2V-cv10-LSVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lsa+tfidf+std-cv-10-LR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "lsa_tfidf_std_syn_w2v_svr = SVR()\n",
    "\n",
    "std_scores = cross_val_score(lsa_tfidf_std_syn_w2v_svr, X_lsa_tfidf_std_syn_w2v, df.hfdfd, cv=10, scoring='mean_squared_error')\n",
    "\n",
    "std_mse = abs(std_scores)\n",
    "print 'LSA+TFIDF+STD+SYN+W2V-cv10-SVR, mse:', std_mse\n",
    "print 'LSA+TFIDF+STD+SYN+W2V-cv10-SVR, mse mean:', np.mean(std_mse)\n",
    "print 'LSA+TFIDF+STD+SYN+W2V-cv10-SVR, rmse:', np.sqrt(std_mse)\n",
    "print 'LSA+TFIDF+STD+SYN+W2V-cv10-SVR, rmse mean:', np.mean(np.sqrt(std_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
